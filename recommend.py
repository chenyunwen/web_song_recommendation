# -*- coding: utf-8 -*-
"""recommend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yNTSeYq0_Ztpm3enc2o3XSG5jc8m1qDb
"""

from sklearn.datasets import load_files
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import os
from gensim import corpora, models, similarities
import joblib
import pickle
import numpy as np
import jieba.analyse
import jieba
import codecs
import pandas as pd
import re

"""# Load lyrics data"""

df = pd.read_csv ('./combine/data/lyric_df.csv')
df

"""# Import testing lyric and preprocess"""

def remove_punctuation(line):
    stopwords = [line.strip() for line in open('./combine/data/stopwords.txt', 'r', encoding='utf-8').readlines()]
    line = str(line)
    if line.strip() == '':
        return ''
    re_han = re.compile(u"[^a-zA-Z0-9\u4E00-\u9FA5]")
    line = re_han.sub('', line)
    cut = [w for w in list(jieba.cut(line)) if w not in stopwords]
    res = " ".join(cut)
    return res

# test_lyric = "會不會 有一天 時間真的能倒退 退回 你的我的 回不去的 悠悠的歲月 也許會 有一天 世界真的有終點 也要和你舉起回憶釀的甜 和你再乾一杯 如果說 要我選出 代表青春 那個畫面 浮現了 那滴眼淚 那片藍天 那年畢業 那一張 邊哭邊笑 還要擁抱 是你的臉 想起來 可愛可憐 可歌可泣 可是多懷念 懷念總是 突然懷念 不談條件 當回憶 衝破考卷 衝出歲月 在我眼前 我和你 流著汗水 喝著汽水 在操場邊 說好了 無論如何 一起走到 未來的世界 現在就是 那個未來 那個世界 為什麼 你的身邊 我的身邊 不是同一邊 友情曾像 諾亞方舟 堅強誓言 只是我 望著海面 等著永遠 模糊了視線 會不會 有一天 時間真的能倒退 退回 你的我的 回不去的 悠悠的歲月 也許會 有一天 世界真的有終點 也要和你舉起回憶釀的甜 和你再乾一杯 這些年 買了四輪 買了手錶 買了單眼 卻發現 追不到的 停不了的 還是那些 人生是 只有認命 只能宿命 只好宿醉 只剩下 高的笑點 低的哭點 卻沒成熟點 成熟就是 幻想幻滅 一場磨練 為什麼 只有夢想 越磨越小 小到不見 有時候 好想流淚 好想流淚 卻沒眼淚 期待會 你會不會 他會不會 開個同學會 他在等你 你在等我 我在等誰 又是誰 孩子沒睡 電話沒電 心情沒準備 天空不斷 黑了又亮 亮了又黑 那光陰 滄海桑田 遠走高飛 再沒力氣追 終究會 有一天 我們都變成昨天 是你 陪我走過 一生一回 匆匆的人間 有一天 就是今天 今天就是有一天 說出一直沒說 對你的感謝 和你再乾一杯 再乾一杯永遠 喝了就能萬歲 歲歲和年年 時間都停了 他們都回來了 懷念的人啊 等你的來到 時間都停了 他們都回來了 懷念的人啊 等你的來到"
# test_lyric_seg = remove_punctuation(test_lyric)

########
def similar_predict(test_lyric):
    """# Get categories

    ## Load TfidfVectorizer and transform lyric to vector
    """
    test_lyric_seg = remove_punctuation(test_lyric)
    with open('./combine/model/vectorizer.pickle', 'rb') as f:
        vectorizer = pickle.load(f)

    tmp = []
    tmp.append(test_lyric_seg)
    test_lyric_vec = vectorizer.transform(tmp)

    """## Load Logistic Regression Model"""

    LR_model = joblib.load('./combine/model/LR_model')

    """## Predict category"""

    predictions = LR_model.predict(test_lyric_vec)
    predictions = predictions[0]
    predictions
    # return test_lyric_seg, predictions

#######

# def similar_predict(test_lyric_seg, predictions):

    """# Find similar lyric"""

    if predictions == '愛情':
        category = 'love'
    elif predictions == '勵志友情':
        category = 'friendship'
    elif predictions == '悲傷離別':
        category = 'sad'
    else:
        category = 'fight'

    condition = df['Category'] == predictions
    df_select = df[condition]
    df_select = df_select.reset_index(drop = True)
    df_select

    # 載入同義字
    word_net = []
    with open("combine/data/synonyms.txt", "r", encoding = "utf-8") as f1:
        for line in f1:
            word_net.append(line)

    word_net = sorted(set(word_net))
    synonyms_dic = {}

    for word in word_net:
        word_s = word.split()
        synonyms_dic[word_s[0]] = word_s[1]

    def synonyms(line):
        line_words = line.split()
        line_lyrics = ""
        for line_word in line_words:
            if line_word in synonyms_dic:
                line_lyrics = line_lyrics + synonyms_dic[line_word] + ' '
            else:
                line_lyrics = line_lyrics + line_word + ' '
        return line_lyrics

    def getTopTen(line):
        words = jieba.analyse.extract_tags(line, 10)
        return words

    doc = synonyms(test_lyric_seg)
    doc_top10 = getTopTen(doc)

    """## Load LDA models"""

    print("combine/data/lyrics_{}.dict".format(category))

    # 載入語料庫
    if (os.path.exists("combine/data/lyrics_{}.dict".format(category))):
        dictionary = corpora.Dictionary.load("combine/data/lyrics_{}.dict".format(category)) # 建立Dictionary
        print(dictionary)
        corpus = corpora.MmCorpus("combine/data/lyrics_{}.mm".format(category)) # 將數據流的語料變為內容流的語料
        print("Used files generated from first tutorial")
        print(corpus)
    else:
        print("Please run first tutorial to generate data set")

    tfidf = models.TfidfModel(corpus)
    # 轉為向量表示
    corpus_tfidf = tfidf[corpus]

    lda_model = models.LsiModel.load('combine/model/lda_model_{}.lda'.format(category))
    vec_bow = dictionary.doc2bow(doc.split()) # 把doc語料庫轉為一個一個詞包
    vec_lsi = lda_model[vec_bow] # 用前面建好的 lsi 模型去計算這一篇歌詞 (input: 斷詞後的詞包、output: 20個主題成分)

    index = similarities.MatrixSimilarity(lda_model[corpus])  # 建立索引
    sims = index[vec_lsi] 
    sims = sorted(enumerate(sims), key = lambda item: -item[1])

    names, lyrics, top10 = [], [], []
    for n, line, ten in zip(list(df_select['Name']), list(df_select['Lyric']), list(df_select['top_10'])):
        names.append(n)
        lyrics.append(line)
        top10.append(ten)

    # for lyric in sims[:5]:
    #     print("\n相似歌詞: ",  names[lyric[0]])
    #     print("TF-IDF top 10: ", top10[lyric[0]])
    #     print(lyrics[lyric[0]])
    #     print("相似度：",  lyric[1])

    song_names = []
    song_lyrics = []
    acc = []
    for lyric in sims[:5]:
        print("\n相似歌詞: ",  names[lyric[0]])
        song_names.append(names[lyric[0]])
        print("TF-IDF top 10: ", top10[lyric[0]])
        print(lyrics[lyric[0]])
        song_lyrics.append(lyrics[lyric[0]])
        print("相似度：",  lyric[1])
        acc.append(lyric[1])  
    return predictions, song_names, song_lyrics, acc

# def all_predict(test_lyric_seg):

    """# Find similar lyric"""

    # if predictions == '愛情':
    #     category = 'love'
    # elif predictions == '勵志友情':
    #     category = 'friendship'
    # elif predictions == '悲傷離別':
    #     category = 'sad'
    # else:
    #     category = 'fight'

    # condition = (df['Category'] == '愛情' or df['Category'] == '勵志友情' or df['Category'] == '悲傷離別' or df['Category'] == '反抗反駁反諷')
    df_select = df #[condition]
    df_select = df_select.reset_index(drop = True)
    df_select

    # 載入同義字
    word_net = []
    with open("data/synonyms.txt", "r", encoding = "utf-8") as f1:
        for line in f1:
            word_net.append(line)

    word_net = sorted(set(word_net))
    synonyms_dic = {}

    for word in word_net:
        word_s = word.split()
        synonyms_dic[word_s[0]] = word_s[1]

    def synonyms(line):
        line_words = line.split()
        line_lyrics = ""
        for line_word in line_words:
            if line_word in synonyms_dic:
                line_lyrics = line_lyrics + synonyms_dic[line_word] + ' '
            else:
                line_lyrics = line_lyrics + line_word + ' '
        return line_lyrics

    def getTopTen(line):
        words = jieba.analyse.extract_tags(line, 10)
        return words

    doc = synonyms(test_lyric_seg)
    doc_top10 = getTopTen(doc)

    """## Load LDA models"""

    print("data/lyrics.dict")

    # 載入語料庫
    if (os.path.exists("data/lyrics.dict")):
        dictionary = corpora.Dictionary.load("data/lyrics.dict") # 建立Dictionary
        print(dictionary)
        corpus = corpora.MmCorpus("data/lyrics.mm") # 將數據流的語料變為內容流的語料
        print("Used files generated from first tutorial")
        print(corpus)
    else:
        print("Please run first tutorial to generate data set")

    tfidf = models.TfidfModel(corpus)
    # 轉為向量表示
    corpus_tfidf = tfidf[corpus]

    lda_model = models.LsiModel.load('model/lda_model.lda')
    vec_bow = dictionary.doc2bow(doc.split()) # 把doc語料庫轉為一個一個詞包
    vec_lsi = lda_model[vec_bow] # 用前面建好的 lsi 模型去計算這一篇歌詞 (input: 斷詞後的詞包、output: 20個主題成分)

    index = similarities.MatrixSimilarity(lda_model[corpus])  # 建立索引
    sims = index[vec_lsi] 
    sims = sorted(enumerate(sims), key = lambda item: -item[1])

    names, lyrics, top10 = [], [], []
    for n, line, ten in zip(list(df_select['Name']), list(df_select['Lyric']), list(df_select['top_10'])):
        names.append(n)
        lyrics.append(line)
        top10.append(ten)

    # for lyric in sims[:5]:
    #     print("\n相似歌詞: ",  names[lyric[0]])
    #     print("TF-IDF top 10: ", top10[lyric[0]])
    #     print(lyrics[lyric[0]])
    #     print("相似度：",  lyric[1])

    song_names = []
    song_lyrics = []
    acc = []
    for lyric in sims[:5]:
        print("\n相似歌詞: ",  names[lyric[0]])
        song_names.append(names[lyric[0]])
        print("TF-IDF top 10: ", top10[lyric[0]])
        print(lyrics[lyric[0]])
        song_lyrics.append(lyrics[lyric[0]])
        print("相似度：",  lyric[1])
        acc.append(lyric[1])  
    return song_names, song_lyrics, acc

